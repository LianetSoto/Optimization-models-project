{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecb2007f",
   "metadata": {},
   "source": [
    "## Definici√≥n de la funci√≥n objetivo y su gradiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45562336",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Definir la funci√≥n objetivo y su gradiente\n",
    "def f(x):\n",
    "    x_clipped = np.clip(x, -100, 100)\n",
    "    return (np.exp(x_clipped[0]) + np.exp(x_clipped[1])) * np.arctan(x_clipped[0]**2 + x_clipped[1]**2)\n",
    "\n",
    "def grad_f(params):\n",
    "    x, y = params\n",
    "    # Limitar los valores para evitar overflow\n",
    "    x_clipped = np.clip(x, -100, 100)\n",
    "    y_clipped = np.clip(y, -100, 100)\n",
    "    \n",
    "    r = x_clipped**2 + y_clipped**2\n",
    "    exp_x = np.exp(x_clipped)\n",
    "    exp_y = np.exp(y_clipped)\n",
    "    arctan_r = np.arctan(r)\n",
    "    denom = 1 + r**2\n",
    "    \n",
    "    fx = exp_x * arctan_r + (exp_x + exp_y) * (2 * x_clipped) / denom\n",
    "    fy = exp_y * arctan_r + (exp_x + exp_y) * (2 * y_clipped) / denom\n",
    "    return np.array([fx, fy])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b445876f",
   "metadata": {},
   "source": [
    "## Graficaci√≥n de funci√≥n objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec874046",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Crear una malla de puntos m√°s densa cerca del origen\n",
    "x = np.linspace(-1.5, 1.5, 150)\n",
    "y = np.linspace(-1.5, 1.5, 150)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "# Evaluar la funci√≥n en cada punto de la malla\n",
    "Z = np.array([f([xi, yi]) for xi, yi in zip(np.ravel(X), np.ravel(Y))]).reshape(X.shape)\n",
    "\n",
    "# Configurar el gr√°fico 3D\n",
    "fig = plt.figure(figsize=(12, 9))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Crear la superficie con colores que resalten el m√≠nimo\n",
    "surf = ax.plot_surface(X, Y, Z, cmap='viridis', alpha=0.9, \n",
    "                      linewidth=0, antialiased=True, rstride=1, cstride=1)\n",
    "\n",
    "# Configurar el √°ngulo de vista para mostrar claramente el m√≠nimo\n",
    "ax.view_init(elev=10, azim=15)  # Elevaci√≥n 10¬∞, azimut 15¬∞\n",
    "\n",
    "# Etiquetas y t√≠tulo\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('f(X, Y)')\n",
    "ax.set_title('Gr√°fico 3D de f(x,y) - M√≠nimo en (0,0)')\n",
    "\n",
    "# A√±adir barra de colores\n",
    "fig.colorbar(surf, ax=ax, shrink=0.5, aspect=5)\n",
    "\n",
    "# A√±adir un punto rojo en el m√≠nimo\n",
    "ax.scatter([0], [0], [f([0,0])], color='red', s=100, label='M√≠nimo (0,0)')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9267851",
   "metadata": {},
   "source": [
    "## Definici√≥n de m√©todos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "075976d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "import numpy as np\n",
    "def gradient_descent(x0, learning_rate=0.01, tol=1e-6, max_iter=10000, c=1e-4, beta=0.8):\n",
    "    x = np.array(x0, dtype=float)\n",
    "    history = [x.copy()]\n",
    "    for _ in range(max_iter):\n",
    "        grad = grad_f(x)\n",
    "        x_new = x - learning_rate * grad\n",
    "        history.append(x_new.copy())\n",
    "        if np.linalg.norm(x_new - x) < tol:\n",
    "            break\n",
    "        x = x_new\n",
    "    return x, history, len(history)\n",
    "\n",
    "# Quasi-Newton usando scipy.optimize.minimize con BFGS y callback para historial\n",
    "class Callback:\n",
    "    def __init__(self):\n",
    "        self.history = []\n",
    "    def __call__(self, xk):\n",
    "        self.history.append(np.array(xk))\n",
    "\n",
    "def quasi_newton(x0, tolerance=1e-6, max_iterations=100):\n",
    "    callback = Callback()\n",
    "    result = minimize(\n",
    "        f, x0, \n",
    "        method='BFGS', \n",
    "        jac=grad_f, \n",
    "        callback=callback,\n",
    "        options={\n",
    "            'gtol': tolerance,\n",
    "            'disp': False, \n",
    "            'maxiter': max_iterations\n",
    "        })\n",
    "    return result, [np.array(x0)] + callback.history, len(callback.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d31885f",
   "metadata": {},
   "source": [
    "## Implementaci√≥n de metodos de graficaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f768dd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graficar_comparativo_resultados(resultados_completos):\n",
    "    \"\"\"Genera gr√°ficos comparativos de todos los resultados\"\"\"\n",
    "    resultados = resultados_completos['resultados']\n",
    "    \n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    nombres = [f\"Caso {i+1}\" for i in range(len(resultados))]\n",
    "    iter_qn = [r['quasi_newton']['iteraciones'] for r in resultados]\n",
    "    iter_gd = [r['descenso_gradiente']['iteraciones'] for r in resultados]\n",
    "    \n",
    "    # Subgr√°fico 1: Iteraciones por m√©todo\n",
    "    x = np.arange(len(nombres))\n",
    "    width = 0.35\n",
    "    ax1.bar(x - width/2, iter_qn, width, label='Quasi-Newton', alpha=0.7)\n",
    "    ax1.bar(x + width/2, iter_gd, width, label='Descenso Gradiente', alpha=0.7)\n",
    "    ax1.set_xlabel('Casos')\n",
    "    ax1.set_ylabel('N√∫mero de Iteraciones')\n",
    "    ax1.set_title('Comparaci√≥n de Iteraciones por M√©todo')\n",
    "    ax1.set_xticks(x)\n",
    "    ax1.set_xticklabels(nombres, rotation=45)\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Subgr√°fico 2: Valor final de la funci√≥n\n",
    "    val_qn = [r['quasi_newton']['valor_final'] for r in resultados]\n",
    "    val_gd = [r['descenso_gradiente']['valor_final'] for r in resultados]\n",
    "    \n",
    "    ax2.semilogy(x, val_qn, 'o-', label='Quasi-Newton', linewidth=2, markersize=8)\n",
    "    ax2.semilogy(x, val_gd, 's-', label='Descenso Gradiente', linewidth=2, markersize=8)\n",
    "    ax2.set_xlabel('Casos')\n",
    "    ax2.set_ylabel('Valor Final f(x) (escala log)')\n",
    "    ax2.set_title('Comparaci√≥n del Valor Final')\n",
    "    ax2.set_xticks(x)\n",
    "    ax2.set_xticklabels(nombres, rotation=45)\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Subgr√°fico 3: Eficiencia relativa\n",
    "    eficiencia = [iter_gd[i]/max(iter_qn[i], 1) for i in range(len(iter_qn))]\n",
    "    ax3.bar(nombres, eficiencia, alpha=0.7, color='orange')\n",
    "    ax3.axhline(y=1, color='red', linestyle='--', label='L√≠mite igualdad')\n",
    "    ax3.set_xlabel('Casos')\n",
    "    ax3.set_ylabel('Iteraciones GD / Iteraciones QN')\n",
    "    ax3.set_title('Eficiencia Relativa: GD vs QN')\n",
    "    ax3.set_xticklabels(nombres, rotation=45)\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Subgr√°fico 4: Resumen estad√≠stico\n",
    "    metodos = ['Quasi-Newton', 'Descenso Gradiente']\n",
    "    iter_promedio = [\n",
    "        resultados_completos['resumen_estadisticas']['quasi_newton']['iteraciones_promedio'],\n",
    "        resultados_completos['resumen_estadisticas']['descenso_gradiente']['iteraciones_promedio']\n",
    "    ]\n",
    "    \n",
    "    ax4.bar(metodos, iter_promedio, alpha=0.7, color=['blue', 'red'])\n",
    "    ax4.set_ylabel('Iteraciones Promedio')\n",
    "    ax4.set_title('Resumen de Iteraciones Promedio')\n",
    "    for i, v in enumerate(iter_promedio):\n",
    "        ax4.text(i, v + 0.1, f'{v:.1f}', ha='center', va='bottom')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def calcular_limites_automaticos(gd_history, qn_history, margen=0.2):\n",
    "    \"\"\"\n",
    "    Calcula l√≠mites autom√°ticos basados en las trayectorias con mejor manejo de casos extremos\n",
    "    \"\"\"\n",
    "    # Convertir a arrays numpy\n",
    "    gd_array = np.array(gd_history)\n",
    "    qn_array = np.array(qn_history)\n",
    "    all_points = np.vstack([gd_array, qn_array])\n",
    "    \n",
    "    x_min, x_max = all_points[:, 0].min(), all_points[:, 0].max()\n",
    "    y_min, y_max = all_points[:, 1].min(), all_points[:, 1].max()\n",
    "    \n",
    "    # Si todos los puntos est√°n muy cerca, usar l√≠mites por defecto\n",
    "    if abs(x_max - x_min) < 1e-10 and abs(y_max - y_min) < 1e-10:\n",
    "        x_lim = (x_min - 2, x_max + 2)\n",
    "        y_lim = (y_min - 2, y_max + 2)\n",
    "    else:\n",
    "        # A√±adir margen proporcional al rango\n",
    "        x_range = x_max - x_min\n",
    "        y_range = y_max - y_min\n",
    "        \n",
    "        # Margen m√≠nimo de 0.5 para evitar l√≠mites demasiado estrechos\n",
    "        x_margin = max(x_range * margen, 0.5)\n",
    "        y_margin = max(y_range * margen, 0.5)\n",
    "        \n",
    "        x_lim = (x_min - x_margin, x_max + x_margin)\n",
    "        y_lim = (y_min - y_margin, y_max + y_margin)\n",
    "    \n",
    "    # Limitar los l√≠mites a un rango razonable para evitar problemas num√©ricos\n",
    "    max_limit = 1000  # L√≠mite m√°ximo para evitar problemas de memoria\n",
    "    x_lim = (max(x_lim[0], -max_limit), min(x_lim[1], max_limit))\n",
    "    y_lim = (max(y_lim[0], -max_limit), min(y_lim[1], max_limit))\n",
    "    \n",
    "    return x_lim, y_lim\n",
    "\n",
    "def graficar_trayectorias_contorno(gd_history, qn_history, caso_nombre, f, x_lim=None, y_lim=None):\n",
    "    \"\"\"\n",
    "    Grafica las trayectorias de optimizaci√≥n en el espacio de b√∫squeda 2D\n",
    "    \n",
    "    Args:\n",
    "        gd_history: Lista de puntos del descenso por gradiente\n",
    "        qn_history: Lista de puntos del quasi-Newton\n",
    "        caso_nombre: Nombre del caso para el t√≠tulo\n",
    "        f: Funci√≥n objetivo\n",
    "        x_lim: L√≠mites del eje x (None para autom√°tico)\n",
    "        y_lim: L√≠mites del eje y (None para autom√°tico)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convertir historiales a arrays\n",
    "    gd_array = np.array(gd_history)\n",
    "    qn_array = np.array(qn_history)\n",
    "    \n",
    "    # Calcular l√≠mites autom√°ticos si no se proporcionan\n",
    "    if x_lim is None or y_lim is None:\n",
    "        x_lim_auto, y_lim_auto = calcular_limites_automaticos(gd_history, qn_history)\n",
    "        x_lim = x_lim if x_lim is not None else x_lim_auto\n",
    "        y_lim = y_lim if y_lim is not None else y_lim_auto\n",
    "    \n",
    "    # Crear malla para el contorno\n",
    "    x = np.linspace(x_lim[0], x_lim[1], 100)\n",
    "    y = np.linspace(y_lim[0], y_lim[1], 100)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    \n",
    "    # Evaluar la funci√≥n en la malla (manejar posibles errores)\n",
    "    try:\n",
    "        Z = np.array([f([xi, yi]) for xi, yi in zip(np.ravel(X), np.ravel(Y))]).reshape(X.shape)\n",
    "    except Exception as e:\n",
    "        print(f\"Error evaluando la funci√≥n: {e}\")\n",
    "        # Usar una funci√≥n por defecto si falla\n",
    "        Z = X**2 + Y**2\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Gr√°fico de contorno con trayectorias\n",
    "    try:\n",
    "        contour = ax1.contour(X, Y, Z, levels=20, alpha=0.6)\n",
    "        ax1.clabel(contour, inline=True, fontsize=8)\n",
    "        ax1.contourf(X, Y, Z, levels=50, alpha=0.3, cmap='viridis')\n",
    "    except Exception as e:\n",
    "        print(f\"Error creando contornos: {e}\")\n",
    "    \n",
    "    # Trayectoria Descenso por Gradiente\n",
    "    ax1.plot(gd_array[:, 0], gd_array[:, 1], 'ro-', linewidth=2, markersize=4, \n",
    "             label='Descenso Gradiente', alpha=0.7)\n",
    "    ax1.scatter(gd_array[0, 0], gd_array[0, 1], color='green', s=100, \n",
    "                label='Inicio', zorder=5)\n",
    "    ax1.scatter(gd_array[-1, 0], gd_array[-1, 1], color='red', s=100, \n",
    "                label='Fin GD', zorder=5)\n",
    "    \n",
    "    # Trayectoria Quasi-Newton\n",
    "    ax1.plot(qn_array[:, 0], qn_array[:, 1], 'bo-', linewidth=2, markersize=4, \n",
    "             label='Quasi-Newton', alpha=0.7)\n",
    "    ax1.scatter(qn_array[-1, 0], qn_array[-1, 1], color='blue', s=100, \n",
    "                label='Fin QN', zorder=5)\n",
    "    \n",
    "    ax1.set_xlabel('X')\n",
    "    ax1.set_ylabel('Y')\n",
    "    ax1.set_title(f'Trayectorias de Optimizaci√≥n - {caso_nombre}')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_xlim(x_lim)\n",
    "    ax1.set_ylim(y_lim)\n",
    "    \n",
    "    # Gr√°fico de convergencia\n",
    "    ax2.semilogy(range(len(gd_history)), [f(p) for p in gd_history], \n",
    "                 'ro-', label='Descenso Gradiente', alpha=0.7)\n",
    "    ax2.semilogy(range(len(qn_history)), [f(p) for p in qn_history], \n",
    "                 'bo-', label='Quasi-Newton', alpha=0.7)\n",
    "    ax2.set_xlabel('Iteraci√≥n')\n",
    "    ax2.set_ylabel('Valor f(x) (escala log)')\n",
    "    ax2.set_title(f'Convergencia - {caso_nombre}')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def graficar_trayectorias_3d(gd_history, qn_history, caso_nombre, f, x_lim=None, y_lim=None):\n",
    "    \"\"\"\n",
    "    Grafica las trayectorias en 3D sobre la superficie de la funci√≥n\n",
    "    \"\"\"\n",
    "    # Convertir historiales a arrays\n",
    "    gd_array = np.array(gd_history)\n",
    "    qn_array = np.array(qn_history)\n",
    "    \n",
    "    # Calcular l√≠mites autom√°ticos si no se proporcionan\n",
    "    if x_lim is None or y_lim is None:\n",
    "        x_lim, y_lim = calcular_limites_automaticos(gd_history, qn_history, margen=0.3)\n",
    "    \n",
    "    # Verificar si los l√≠mites son muy grandes y ajustar la resoluci√≥n\n",
    "    x_range = x_lim[1] - x_lim[0]\n",
    "    y_range = y_lim[1] - y_lim[0]\n",
    "    \n",
    "    # Ajustar resoluci√≥n basada en el rango\n",
    "    if max(x_range, y_range) > 50:\n",
    "        resolution = 30  # Baja resoluci√≥n para rangos grandes\n",
    "    elif max(x_range, y_range) > 20:\n",
    "        resolution = 50  # Resoluci√≥n media\n",
    "    else:\n",
    "        resolution = 80  # Alta resoluci√≥n para rangos peque√±os\n",
    "    \n",
    "    print(f\"   üìê Resoluci√≥n 3D: {resolution}x{resolution} para rango X: {x_range:.2f}, Y: {y_range:.2f}\")\n",
    "    \n",
    "    # Crear malla\n",
    "    x = np.linspace(x_lim[0], x_lim[1], resolution)\n",
    "    y = np.linspace(y_lim[0], y_lim[1], resolution)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    \n",
    "    # Evaluar la funci√≥n en la malla con manejo de errores robusto\n",
    "    try:\n",
    "        # Vectorizar la evaluaci√≥n si es posible\n",
    "        Z = np.zeros_like(X)\n",
    "        for i in range(X.shape[0]):\n",
    "            for j in range(X.shape[1]):\n",
    "                try:\n",
    "                    Z[i, j] = f([X[i, j], Y[i, j]])\n",
    "                except:\n",
    "                    Z[i, j] = 0  # Valor por defecto en caso de error\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è  Error evaluando funci√≥n 3D: {e}\")\n",
    "        # Crear una superficie simple como fallback\n",
    "        Z = X**2 + Y**2\n",
    "    \n",
    "    # Calcular valores Z para las trayectorias\n",
    "    try:\n",
    "        gd_z = [f(p) for p in gd_history]\n",
    "        qn_z = [f(p) for p in qn_history]\n",
    "    except:\n",
    "        # Fallback para trayectorias\n",
    "        gd_z = [p[0]**2 + p[1]**2 if len(p) > 1 else 0 for p in gd_history]\n",
    "        qn_z = [p[0]**2 + p[1]**2 if len(p) > 1 else 0 for p in qn_history]\n",
    "    \n",
    "    fig = plt.figure(figsize=(16, 7))\n",
    "    \n",
    "    # Vista 3D 1 - Perspectiva est√°ndar\n",
    "    ax1 = fig.add_subplot(121, projection='3d')\n",
    "    try:\n",
    "        # Usar plot_surface con par√°metros optimizados\n",
    "        surf1 = ax1.plot_surface(X, Y, Z, cmap='viridis', alpha=0.7, \n",
    "                                linewidth=0, antialiased=True, rstride=1, cstride=1)\n",
    "        \n",
    "        # A√±adir barra de color\n",
    "        fig.colorbar(surf1, ax=ax1, shrink=0.5, aspect=20, label='f(x,y)')\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è  Error creando superficie 3D: {e}\")\n",
    "    \n",
    "    # Trayectorias con mejor visibilidad\n",
    "    ax1.plot(gd_array[:, 0], gd_array[:, 1], gd_z, 'ro-', linewidth=3, \n",
    "             label='Descenso Gradiente', markersize=6, alpha=0.8)\n",
    "    ax1.plot(qn_array[:, 0], qn_array[:, 1], qn_z, 'bo-', linewidth=3, \n",
    "             label='Quasi-Newton', markersize=6, alpha=0.8)\n",
    "    \n",
    "    # Puntos inicial y final\n",
    "    ax1.scatter([gd_array[0, 0]], [gd_array[0, 1]], [gd_z[0]], \n",
    "                color='green', s=200, label='Inicio', marker='*')\n",
    "    ax1.scatter([gd_array[-1, 0]], [gd_array[-1, 1]], [gd_z[-1]], \n",
    "                color='red', s=150, label='Fin GD', marker='s')\n",
    "    ax1.scatter([qn_array[-1, 0]], [qn_array[-1, 1]], [qn_z[-1]], \n",
    "                color='blue', s=150, label='Fin QN', marker='^')\n",
    "    \n",
    "    ax1.set_xlabel('X')\n",
    "    ax1.set_ylabel('Y')\n",
    "    ax1.set_zlabel('f(X, Y)')\n",
    "    ax1.set_title(f'Trayectorias 3D - {caso_nombre}\\nRango: X[{x_lim[0]:.1f},{x_lim[1]:.1f}] Y[{y_lim[0]:.1f},{y_lim[1]:.1f}]')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "\n",
    "    # Vista 3D 2 - Perspectiva a√©rea\n",
    "    ax2 = fig.add_subplot(122, projection='3d')\n",
    "    try:\n",
    "        surf2 = ax2.plot_surface(X, Y, Z, cmap='viridis', alpha=0.7, \n",
    "                                linewidth=0, antialiased=True, rstride=1, cstride=1)\n",
    "        fig.colorbar(surf2, ax=ax2, shrink=0.5, aspect=20, label='f(x,y)')\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è  Error creando superficie 3D (vista 2): {e}\")\n",
    "    \n",
    "    # Mismas trayectorias\n",
    "    ax2.plot(gd_array[:, 0], gd_array[:, 1], gd_z, 'ro-', linewidth=3, \n",
    "             label='Descenso Gradiente', markersize=6, alpha=0.8)\n",
    "    ax2.plot(qn_array[:, 0], qn_array[:, 1], qn_z, 'bo-', linewidth=3, \n",
    "             label='Quasi-Newton', markersize=6, alpha=0.8)\n",
    "    \n",
    "    # Puntos\n",
    "    ax2.scatter([gd_array[0, 0]], [gd_array[0, 1]], [gd_z[0]], \n",
    "                color='green', s=200, label='Inicio', marker='*')\n",
    "    ax2.scatter([gd_array[-1, 0]], [gd_array[-1, 1]], [gd_z[-1]], \n",
    "                color='red', s=150, label='Fin GD', marker='s')\n",
    "    ax2.scatter([qn_array[-1, 0]], [qn_array[-1, 1]], [qn_z[-1]], \n",
    "                color='blue', s=150, label='Fin QN', marker='^')\n",
    "    \n",
    "    # Vista desde arriba\n",
    "    ax2.view_init(elev=80, azim=-90)  # Vista a√©rea\n",
    "    ax2.set_xlabel('X')\n",
    "    ax2.set_ylabel('Y')\n",
    "    ax2.set_zlabel('f(X, Y)')\n",
    "    ax2.set_title(f'Vista A√©rea - {caso_nombre}')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def visualizar_caso_completo(gd_history, qn_history, case_name):\n",
    "    \"\"\"\n",
    "    Visualiza un caso espec√≠fico con todos los gr√°ficos\n",
    "    \"\"\"\n",
    "    # Calcular l√≠mites autom√°ticos\n",
    "    x_lim, y_lim = calcular_limites_automaticos(gd_history, qn_history, margen=0.3)\n",
    "    \n",
    "    # Graficar\n",
    "    graficar_trayectorias_contorno(gd_history, qn_history, case_name, f, x_lim, y_lim)\n",
    "    graficar_trayectorias_3d(gd_history, qn_history, case_name, f, x_lim, y_lim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf221a1",
   "metadata": {},
   "source": [
    "## Ejecuci√≥n de experimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83fabba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "def ejecutar_experimentos(archivo_json: str, archivo_salida: str = \"resultados_experimentos.json\", mostrar_graficos_individuales = True):\n",
    "    \"\"\"\n",
    "    Carga casos de prueba desde un archivo JSON, ejecuta los experimentos\n",
    "    y guarda los resultados en otro archivo JSON.\n",
    "    \n",
    "    Args:\n",
    "        archivo_json: Ruta del archivo JSON con los casos de prueba\n",
    "        archivo_salida: Ruta del archivo JSON donde se guardar√°n los resultados\n",
    "    \"\"\"\n",
    "    print(\"INICIANDO EXPERIMENTACI√ìN\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Cargar datos desde JSON\n",
    "    try:\n",
    "        with open(archivo_json, 'r', encoding='utf-8') as file:\n",
    "            datos = json.load(file)\n",
    "        \n",
    "        casos_prueba = datos.get(\"casos_prueba\", [])\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Archivo {archivo_json} no encontrado\")\n",
    "        return\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Archivo {archivo_json} no es un JSON v√°lido\")\n",
    "        return\n",
    "   \n",
    "    resultados_totales = []\n",
    "    historiales_completos = {}\n",
    "    \n",
    "    # Ejecutar cada caso de prueba \n",
    "    for i, caso in enumerate(casos_prueba, 1):\n",
    "        print(f\"\\nCaso {i}: {caso.get('name', f'Caso {i}')}\")\n",
    "        print(f\"   Punto inicial: {caso['x0']}\")\n",
    "        print(f\"   Par√°metros - LR: {caso['learning_rate']}, \"\n",
    "              f\"Tol: {caso['tolerance']}, MaxIter: {caso['max_iterations']}\")\n",
    "        \n",
    "        # Convertir a numpy array\n",
    "        x0 = np.array(caso['x0'])\n",
    "        \n",
    "        # Ejecutar Quasi-Newton\n",
    "        qn_result, qn_history, qn_iter = quasi_newton(x0, caso['tolerance'], caso['max_iterations'])\n",
    "         \n",
    "        print(f\"Procesando caso {i}...\")      \n",
    "        # Ejecutar Descenso por Gradiente\n",
    "        gd_optimo, gd_history, gd_iter = gradient_descent(\n",
    "            x0, learning_rate= caso['learning_rate'], \n",
    "            tol = caso['tolerance'], max_iter= caso['max_iterations']\n",
    "        )\n",
    "        \n",
    "        # Almacenar resultados - SIN historiales\n",
    "        resultado_caso = {\n",
    "            'nombre': caso.get('name', f'Caso {i}'),\n",
    "            'punto_inicial': caso['x0'],\n",
    "            'parametros': {\n",
    "                'learning_rate': float(caso['learning_rate']),\n",
    "                'tolerance': float(caso['tolerance']),\n",
    "                'max_iterations': int(caso['max_iterations'])\n",
    "            },\n",
    "            'quasi_newton': {\n",
    "                'optimo': qn_result.x.tolist() if hasattr(qn_result, 'x') else qn_result.tolist(),\n",
    "                'iteraciones': int(qn_iter),\n",
    "                'valor_final': float(f(qn_result.x if hasattr(qn_result, 'x') else qn_result))\n",
    "            },\n",
    "            'descenso_gradiente': {\n",
    "                'optimo': gd_optimo.tolist(),\n",
    "                'iteraciones': int(gd_iter),\n",
    "                'valor_final': float(f(gd_optimo))\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        resultados_totales.append(resultado_caso)\n",
    "\n",
    "        # Guardar historiales para graficar\n",
    "        historiales_completos[f'Caso_{i}'] = {\n",
    "            'nombre': caso.get('name', f'Caso {i}'),\n",
    "            'gd_history': gd_history,\n",
    "            'qn_history': qn_history,\n",
    "            'punto_inicial': caso['x0']\n",
    "        }\n",
    "        \n",
    "        # Mostrar gr√°ficos individuales si est√° activado\n",
    "        if mostrar_graficos_individuales:\n",
    "            print(f\"   üìà Generando gr√°ficos para Caso {i}...\")\n",
    "            # graficar_trayectorias_3d(gd_history, qn_history, f\"Caso {i}\")\n",
    "            # graficar_trayectorias_contorno(gd_history, qn_history, f\"Caso {i}\")\n",
    "            visualizar_caso_completo(gd_history,qn_history,f\"Caso {i}\")\n",
    "    \n",
    "    # Crear estructura completa de resultados\n",
    "    resultados_completos = {\n",
    "        'metadata': {\n",
    "            'fecha_ejecucion': datetime.now().isoformat(),\n",
    "            'total_casos': len(resultados_totales),\n",
    "            'funcion_objetivo': 'f(x)'  # Puedes personalizar esto\n",
    "        },\n",
    "        'resultados': resultados_totales,\n",
    "        'resumen_estadisticas': {\n",
    "            'quasi_newton': {\n",
    "                'iteraciones_promedio': float(np.mean([r['quasi_newton']['iteraciones'] for r in resultados_totales])),\n",
    "                'valor_promedio': float(np.mean([r['quasi_newton']['valor_final'] for r in resultados_totales])),\n",
    "                'iteraciones_totales': int(sum([r['quasi_newton']['iteraciones'] for r in resultados_totales]))\n",
    "            },\n",
    "            'descenso_gradiente': {\n",
    "                'iteraciones_promedio': float(np.mean([r['descenso_gradiente']['iteraciones'] for r in resultados_totales])),\n",
    "                'valor_promedio': float(np.mean([r['descenso_gradiente']['valor_final'] for r in resultados_totales])),\n",
    "                'iteraciones_totales': int(sum([r['descenso_gradiente']['iteraciones'] for r in resultados_totales]))\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Guardar resultados en archivo JSON\n",
    "    try:\n",
    "        with open(archivo_salida, 'w', encoding='utf-8') as file:\n",
    "            json.dump(resultados_completos, file, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"‚úÖ RESULTADOS GUARDADOS EXITOSAMENTE\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"Archivo: {archivo_salida}\")\n",
    "        print(f\"Total de casos procesados: {len(resultados_totales)}\")\n",
    "        print(f\"Fecha de ejecuci√≥n: {resultados_completos['metadata']['fecha_ejecucion']}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error al guardar los resultados: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Mostrar gr√°fico comparativo final\n",
    "    print(f\"\\nüìà GENERANDO GR√ÅFICOS COMPARATIVOS FINALES...\")\n",
    "    graficar_comparativo_resultados(resultados_completos)\n",
    "    return resultados_completos, historiales_completos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4320f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "ejecutar_experimentos(\"casos_prueba.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
